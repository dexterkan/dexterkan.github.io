---
title: Lowâ€‘Latency Private ML inference for Vision Tasks in Distributed Environments
authors:
- Te-Yi Kan
- Konstantinos Psounis
date: '2025-01-01'
publishDate: '2025-05-29T21:00:05.329005Z'
publication_types:
- paper-conference
publication: '*Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Submitted*'
publication_short: "WACV"

abstract: "<div style='text-align: justify;'>Machine learning (ML) models for vision tasks, such as object detection and instance segmentation, are essential for applications like human activity monitoring and mixed reality. However, the computational demands of these models typically exceed the capability of mobile devices. A prominent solution is to deploy them on remote servers in distributed environments to optimize utility and reduce latency. This setup, however, requires users to share personal data with remote servers, posing potential privacy risks. To address this challenge, we propose a system we name LLPRI that enables Low-Latency PRivate ML Inference for vision tasks within distributed environments. LLPRI comprises three key modules, a sensitive object detector, a scheduler, and an obfuscator, to balance privacy, utility, and latency for the target task. Experimental result show that our proposed system effectively protects user privacy with low latency overhead while maintaining the utility of the target task.</div>"

summary: "<div style='text-align: justify;'>Machine learning (ML) models for vision tasks, such as object detection and instance segmentation, are essential for applications like human activity monitoring and mixed reality. However, the computational demands of these models typically exceed the capability of mobile devices. A prominent solution is to deploy them on remote servers in distributed environments to optimize utility and reduce latency. This setup, however, requires users to share personal data with remote servers, posing potential privacy risks. To address this challenge, we propose a system we name LLPRI that enables Low-Latency PRivate ML Inference for vision tasks within distributed environments. LLPRI comprises three key modules, a sensitive object detector, a scheduler, and an obfuscator, to balance privacy, utility, and latency for the target task. Experimental result show that our proposed system effectively protects user privacy with low latency overhead while maintaining the utility of the target task.</div>"

featured: true
---
